{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53c781c",
   "metadata": {},
   "source": [
    "# Model selection & comparison\n",
    "\n",
    "_Alex Malz (LINCC@CMU)_\n",
    "_LSSTC Data Science Fellowship Program_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774035bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import cosmology as apcosmo\n",
    "import numpy as np\n",
    "import scipy.stats as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7492099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8463ac",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Let's try to infer the cosmological parameters from redshifts and distances to Type Ia SNe.\n",
    "This problem is adapted from [Supernova Cosmology Inference with Probabilistic Photometric Redshifts (SCIPPR)](https://github.com/aimalz/scippr), specifically the [forward model](https://github.com/aimalz/scippr/blob/master/code/demos/Simulation.ipynb) and [posterior inference](https://github.com/aimalz/scippr/blob/master/code/demos/Inference.ipynb) procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b78784",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "__TODO__: fix formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed94de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planck values\n",
    "prior_H0 = sps.norm(loc=67.4, scale=0.5)\n",
    "prior_Om0 = sps.norm(loc=0.315, scale=0.007)\n",
    "true_H0 = prior_H0.rvs()\n",
    "true_Om0 = prior_Om0.rvs()\n",
    "print(f'$H_{{0}}^{{true}}=${true_H0}, $\\Omega_{{m}}^{{true}}=${true_Om0}')\n",
    "true_cosmo = apcosmo.FlatLambdaCDM(H0=true_H0, Om0=true_Om0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8236d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nz_func(z, c=0.3):\n",
    "#     return 1./(2.*c) * (z/c)**2 * np.exp(-1. * z/c)\n",
    "nz_true = sps.gamma(3, scale=0.3)\n",
    "zs_true = nz_true.rvs(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a533dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(zs_true);\n",
    "plt.xlabel(r'$z$')\n",
    "plt.title('SNIa redshift distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35b0667",
   "metadata": {},
   "outputs": [],
   "source": [
    "mus_true = true_cosmo.distmod(zs_true).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(zs_true, mus_true)\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$\\mu$')\n",
    "plt.title('true Hubble diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecab7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias_lsst = 0.003\n",
    "# scatter_lsst = 0.02\n",
    "# outlier_lsst = 0.1\n",
    "\n",
    "z_min = 0.\n",
    "z_max = 3.\n",
    "# z_norm_low_true = (z_min - zs_true - bias_lsst * (1 + zs_true)) / (scatter_lsst * (1+zs_true))\n",
    "# z_norm_high_true = (z_max - zs_true - bias_lsst * (1 + zs_true)) / (scatter_lsst * (1+zs_true))\n",
    "# zs_pdf_true = sps.truncnorm(z_norm_low_true, z_norm_high_true, loc=zs_true+bias_lsst, scale=scatter_lsst*(1+zs_true))\n",
    "# zs_obs = zs_pdf_true.rvs()\n",
    "# z_norm_low_obs = (z_min - zs_obs - bias_lsst * (1 + zs_obs)) / (scatter_lsst * (1+zs_obs))\n",
    "# z_norm_high_obs = (z_max - zs_obs - bias_lsst * (1 + zs_obs)) / (scatter_lsst * (1+zs_obs))\n",
    "# zs_pdf_obs = sps.truncnorm(z_norm_low_obs, z_norm_high_obs, loc=zs_obs+bias_lsst, scale=scatter_lsst*(1+zs_obs))\n",
    "# zs_est = zs_pdf_obs.rvs()\n",
    "zs_est = zs_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3208cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(zs_true, zs_est)\n",
    "# plt.xlabel(r'$z_{true}$')\n",
    "# plt.ylabel(r'$z_{obs}$')\n",
    "# plt.title('redshift uncertainties')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c673718b",
   "metadata": {},
   "source": [
    "__TODO: look up realistic mu error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2778923",
   "metadata": {},
   "outputs": [],
   "source": [
    "mus_err = (1. + zs_est) / z_max\n",
    "mus_err_dist = sps.norm(loc=mus_true, scale=mus_err)\n",
    "mus_obs = mus_err_dist.rvs()\n",
    "mus_pdf_obs = sps.norm(loc=mus_obs, scale=mus_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mus_true, mus_obs)\n",
    "plt.xlabel(r'$\\mu_{true}$')\n",
    "plt.ylabel(r'$\\mu_{obs}$')\n",
    "plt.title('distance modulus uncertainties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c410a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(zs_est, mus_obs, #xerr=scatter_lsst*(1.+zs_est), \n",
    "             yerr=mus_err, fmt='.')\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$\\mu$')\n",
    "plt.title('observed Hubble diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a85323",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ae313",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_grid = np.linspace(z_min, z_max, 100)\n",
    "est_H0 = prior_H0.rvs()\n",
    "est_Om0 = prior_Om0.rvs()\n",
    "est_cosmo = apcosmo.FlatLambdaCDM(H0=est_H0, Om0=est_Om0)\n",
    "mus_est = est_cosmo.distmod(z_grid).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_w0 = sps.norm(loc=0.89, scale=0.13)\n",
    "new_cosmo = apcosmo.wCDM(est_H0, est_Om0, 1.-est_Om0, w0=prior_w0.rvs())\n",
    "mus_new = new_cosmo.distmod(z_grid).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(zs_est, mus_obs, #xerr=scatter_lsst*(1.+zs_est), \n",
    "             yerr=mus_err, fmt='.', c='k', alpha=0.5)\n",
    "plt.plot(z_grid, true_cosmo.distmod(z_grid).value, label='true model')\n",
    "plt.plot(z_grid, mus_est, label='estimated model')\n",
    "plt.plot(z_grid, mus_new, label='misspecified model')\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$\\mu$')\n",
    "plt.title('observed Hubble diagram with models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74878e",
   "metadata": {},
   "source": [
    "## Goodness-of-fit & hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab41c36",
   "metadata": {},
   "source": [
    "### Problem 0a\n",
    "\n",
    "Implement a function calculating the reduced $\\chi^{2} = \\sum_{i=1}^{N}\\left(\\frac{y_{i} - M_{i}(\\theta)}{\\sigma_{i}}\\right)^{2}$ and calculate the $\\chi^{2}$ for the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180ea8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_sq(model, xvals, yvals_obs, yerrs_obs):\n",
    "    \"\"\"\n",
    "    Calculates the $chi^{2}$ statistic\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: function\n",
    "        function taking xvals and producing yvals\n",
    "    xvals: array, float\n",
    "        values of the independent variable at which yvals_obs were measured\n",
    "    yvals_obs: array, float\n",
    "        values of the dependent variable at xvals\n",
    "    yerrs_obs:\n",
    "        errors on dependent variable observations\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    chi_sq: float\n",
    "        value of the $\\chi^{2}$ statistic\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(chi_sq(est_cosmo, zs_est, mus_obs, mus_err))\n",
    "# print(chi_sq(new_cosmo, zs_est, mus_obs, mus_err))\n",
    "\n",
    "# make a grid of values for cosmological parameters, plot both on same axes at all points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6cccf",
   "metadata": {},
   "source": [
    "### Problem 0b\n",
    "\n",
    "Minimize the $\\chi^{2}$ to find the maximum likelihood estimator of the cosmological parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70219ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06a94536",
   "metadata": {},
   "source": [
    "### Problem 1a\n",
    "\n",
    "Implement a function empirically calculating the Fisher matrix $F$ where $F_{ij} = \\frac{1}{2}\\frac{\\partial^{2}}{\\partial\\theta_{i}\\partial\\theta_{j}}\\chi^{2}(M, \\theta)$.\n",
    "When is $F^{-1}_{i,j} = \\sigma_{i}\\sigma_{j}$? (When likelihood is Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outline helper functions from https://github.com/COINtoolbox/RESSPECT/blob/master/resspect/cosmo_metric_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher(model, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c699af",
   "metadata": {},
   "source": [
    "### Problem 1b\n",
    "\n",
    "Implement a function that plots error ellipses given a Fisher matrix.\n",
    "This is a useful thing to have around -- I'm still recycling code I wrote to do this in grad school!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46009870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_to_ellipse(fisher_mat):\n",
    "    \n",
    "def plot_ellipse(semimajor, semiminor):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272df60",
   "metadata": {},
   "source": [
    "## Information theory & likelihoods\n",
    "\n",
    "I really want to introduce you to metrics from the perspective of information theory, but more appropriate data for the problem will be available for the experimental design lecture.\n",
    "\n",
    "KLD/relative entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f1998",
   "metadata": {},
   "source": [
    "## Model comparison\n",
    "\n",
    "$AIC = 2\\log[p(data | \\theta)] - 2N_{param}$\n",
    "\n",
    "$BIC = 2\\log[p(data | \\theta)] + N_{param}\\log[N_{data}]$ \n",
    "\n",
    "$\\dots$\n",
    "\n",
    "Sometimes these are defined as negative of what's shown here -- \n",
    "\n",
    "__TODO: Is the $N_{data}$ MCMC samples or something to do with the actual data?__ number of points upon which likelihood is based, so if MCMC sampling to obtain the likelihood, would be number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd1b97",
   "metadata": {},
   "source": [
    "# might develop simple example to model comparison rather than introducing some real outside data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4051347c",
   "metadata": {},
   "source": [
    "Let's look at the MCMC chains from [Chang+18](https://doi.org/10.1093/mnras/sty2902).\n",
    "\n",
    "__TODO: explain the scenarios__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and parse here\n",
    "# pull out likelihoods, number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c41e80",
   "metadata": {},
   "source": [
    "### Problem 2a\n",
    "\n",
    "Write functions for each of the above information criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620391a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aic():"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e1194a",
   "metadata": {},
   "source": [
    "### Problem 2b\n",
    "\n",
    "Compare each dataset's cosmological constraints over $S_{8}$ under the published and matched scenarios and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83be7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f685f6ca",
   "metadata": {},
   "source": [
    "### Problem 2c\n",
    "\n",
    "Compare the matched-assumption constraints across all the data sets and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b14252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05996fb6",
   "metadata": {},
   "source": [
    "## Bayesian metrics\n",
    "\n",
    "The Bayes Factor $BF_{0,1} = \\frac{\\frac{P(\\Theta_{0} | x)}{P(\\Theta_{1} | x)}}{\\frac{P(\\Theta_{0})}{P(\\Theta_{1})}} = \\frac{\\int_{\\Theta_{0}}f(x|\\theta)g_{0}(\\theta)d\\theta}{\\int_{\\Theta_{1}}f(x|\\theta)g_{1}(\\theta)d\\theta}$ compares posteriors estimated from the same data.\n",
    "In Chang+18, we technically had different data, so it wasn't entirely kosher to calculate it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9ecd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSFP (Python 3)",
   "language": "python",
   "name": "dsfp_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
