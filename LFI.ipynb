{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d492bc3",
   "metadata": {},
   "source": [
    "# Likelihood-free Inference\n",
    "\n",
    "_Alex Malz (LINCC@CMU)_\n",
    "_LSSTC Data Science Fellowship Program #16_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9e184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet jax-cosmo numpyro dm-haiku optax sbi chainconsumer tensorflow-probability numpyro lenstools pzflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec6776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax_cosmo as jc\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import numpyro\n",
    "from numpyro.handlers import seed, trace, condition\n",
    "import numpyro.distributions as dist\n",
    "\n",
    "import tensorflow_probability as tfp; tfp = tfp.substrates.jax\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import haiku as hk\n",
    "seq = hk.PRNGSequence(42)\n",
    "\n",
    "import torch\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "\n",
    "from chainconsumer import ChainConsumer\n",
    "\n",
    "import lenstools as lt\n",
    "import astropy.units as u\n",
    "\n",
    "import pzflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d00f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sadly there's a bug due to a deprecated jax function so we can't do the cool thing using this )-;\n",
    "# !pip install --quiet git+https://github.com/EiffL/powerbox-jax.git\n",
    "# import powerbox_jax as pbj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd16129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f44ee",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "When explicit likelihoods are unavailable, we can't do MCMC sampling, so we need alternatives.\n",
    "Those that use an _implicit_ likelihood, in the form of any process that takes in the parameters we want to constrain and outputs realizations of data, form a family of closely related methods called Likelihood-free Inference (LFI), which may also be referred to as Simulation-based Inference (SBI) and which includes Approximate Bayesian Computation (ABC).\n",
    "\n",
    "![overview](01_algorithms_tikz.png \"terminology\")\n",
    "\n",
    "This diagram from [Lueckmann+ 2021](https://arxiv.org/abs/2101.04653), via [Lanusse 2022](https://eiffl.github.io/talks/EAS2022/), illustrates the nuances between terminology for these methods, which seem to change every few years, but the principle behind them is the same.\n",
    "Instead of evaluating the likelihood of proposed parameters, a black-box implicit likelihood, typically a simulator or emulator, is used to forward-model mock data that is then compared with the real data.\n",
    "In both approaches, sampled parameters that are accepted are used to generate subsequent samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c468cfeb",
   "metadata": {},
   "source": [
    "## Astrophysical context\n",
    "\n",
    "Let's try to learn the cosmological parameters from summary statistics of weak lensing mass maps, with and without using the likelihood.\n",
    "This problem is distilled from [a tutorial](https://colab.research.google.com/drive/1K8cB1h3ge3kTVut81Xnkw2kNiKFIn8HI?usp=sharing) by Francois Lanusse;\n",
    "all errors are mine.\n",
    "\n",
    "Let's start by forward modeling weak lensing mass maps.\n",
    "(This uses a lot of `jax` magic I'm not an expert in, so it's a bit of a black box to me, but that's also why it's fast enough to run in a problem session.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LensingForwardModelLogNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b2f942",
   "metadata": {},
   "source": [
    "Our summary statistic will be the weak lensing power spectrum, which is basically an angular correlation function in Fourier space.\n",
    "(A surprisingly good introduction to the power spectrum can be found [here](https://www.astro.caltech.edu/~george/ay21/eaa/eaa-powspec.pdf).)\n",
    "Our physical model will try to generate weak lensing mass maps whose power spectra are close to that of our \"observations\".\n",
    "The guts of the physical model are `make_power_map()` and `make_lognormal_power_map`, which generate the mass map itself and then (optionally) convolve it with a lognormal lensing kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7edb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_power_map(pk_fn, N, field_size, zero_freq_val=0.0):\n",
    "    k = 2*jnp.pi*jnp.fft.fftfreq(N, d=field_size / N)\n",
    "    kcoords = jnp.meshgrid(k,k)\n",
    "    k = jnp.sqrt(kcoords[0]**2 + kcoords[1]**2)\n",
    "    ps_map = pk_fn(k)\n",
    "    ps_map = ps_map.at[0,0].set(zero_freq_val)\n",
    "    return ps_map * (N / field_size)**2\n",
    "\n",
    "def make_lognormal_power_map(power_map, shift, zero_freq_val=0.0):\n",
    "    power_spectrum_for_lognorm = jnp.fft.ifft2(power_map).real\n",
    "    power_spectrum_for_lognorm = jnp.log(1 + power_spectrum_for_lognorm/shift**2)\n",
    "    power_spectrum_for_lognorm = jnp.abs(jnp.fft.fft2(power_spectrum_for_lognorm))\n",
    "    power_spectrum_for_lognorm = power_spectrum_for_lognorm.at[0,0].set(0.)\n",
    "    return power_spectrum_for_lognorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8337b",
   "metadata": {},
   "source": [
    "The simulation model makes mass maps from the cosmological parameters.\n",
    "The priors on the cosmological parameters ($\\Omega_{c}$ and $\\sigma_{8}$ here) enter here, and you can try making more versions of the model function to try different priors.\n",
    "There's also a latent variable, which can represent something like initial conditions, or you can imagine it as being where in the sky you're looking (maybe).\n",
    "\n",
    "The simulation model has some free parameters that affect the time it will take to run as well as how interesting it is.\n",
    "Higer `N` will expand the dimensionality of the data.\n",
    "Make sure `map_size` and `gal_per_arcmin2` don't conspire to give you no galaxies in your map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c08c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(N=128,               # number of pixels on the map\n",
    "          map_size=10,         # map size in deg.\n",
    "          gal_per_arcmin2=10,   \n",
    "          sigma_e=0.2, \n",
    "          shift=0.05,\n",
    "          model_type='lognormal'): # either 'lognormal' or 'gaussian'      \n",
    "    \n",
    "    pix_area = (map_size * 60 / N)**2 # arcmin2 \n",
    "    map_size = map_size / 180 * jnp.pi    # radians\n",
    "\n",
    "    # Sampling cosmology\n",
    "    omega_c = numpyro.sample('omega_c', dist.Normal(0., 1.0)) * 0.05 + 0.3\n",
    "    sigma_8 = numpyro.sample('sigma_8', dist.Normal(0., 1.0)) * 0.05 + 0.8\n",
    "    \n",
    "    cosmo = jc.Planck15(Omega_c=omega_c, sigma8=sigma_8)\n",
    "    # Creating a given redshift distribution\n",
    "    pz = jc.redshift.smail_nz(0.5, 2., 1.0)\n",
    "    tracer = jc.probes.WeakLensing([pz])\n",
    "    \n",
    "    # Defining the function that will compute the power spectrum of the field\n",
    "    # Create an interpolation array for the cls to avoid far too many computations\n",
    "    ell_tab = jnp.logspace(0, 4.5, 128)\n",
    "    cell_tab = jc.angular_cl.angular_cl(cosmo, ell_tab, [tracer])[0]\n",
    "    P = lambda k: jc.scipy.interpolate.interp(k.flatten(), ell_tab, cell_tab).reshape(k.shape)\n",
    "    \n",
    "    # Sampling latent variables\n",
    "    z = numpyro.sample('z', dist.MultivariateNormal(loc=jnp.zeros((N,N)), precision_matrix=jnp.eye(N)))\n",
    "\n",
    "    # Convolving by the power spectrum\n",
    "    power_map = make_power_map(P, N, map_size) \n",
    "    if model_type == 'lognormal':\n",
    "        power_map =  make_lognormal_power_map(power_map, shift)\n",
    "\n",
    "    field = jnp.fft.ifft2(jnp.fft.fft2(z) * jnp.sqrt(power_map)).real\n",
    "\n",
    "    if model_type == 'lognormal':\n",
    "        field = shift * (jnp.exp(field - jnp.var(field) / 2) - 1)\n",
    "\n",
    "    # Adding \"observational noise\"\n",
    "    x = numpyro.sample('x', dist.Independent(dist.Normal(field, sigma_e/jnp.sqrt(gal_per_arcmin2 * pix_area)), 2))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e08ad",
   "metadata": {},
   "source": [
    "Now we can generate weak lensing mass maps for arbitrary values of the cosmological parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our fiducial observations\n",
    "fiducial_model = condition(model, {'omega_c': 0., 'sigma_8': 0.})\n",
    "sample_map_fiducial = seed(fiducial_model, jax.random.PRNGKey(42))\n",
    "m_data = sample_map_fiducial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c5a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m_data, extent=(0,10,0,10))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4215fac",
   "metadata": {},
   "source": [
    "We can look at multiple draws with the same cosmological parameters to see how the latent variables affect the maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_m_data = sample_map_fiducial()\n",
    "plt.imshow(other_m_data, extent=(0,10,0,10))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aabdaf",
   "metadata": {},
   "source": [
    "### The summary statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e379b4c",
   "metadata": {},
   "source": [
    "We'll use the power spectrum as a summary statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23150b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmap_lt = lt.ConvergenceMap(m_data, 10*u.deg)\n",
    "l_edges = np.arange(100.0,3000.0,100.0)\n",
    "l2,Pl2 = kmap_lt.powerSpectrum(l_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f223290",
   "metadata": {},
   "source": [
    "Let's compare against the power spectrum predicted by the cosmological parameters from Planck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that the power spectrum looks ok with Lenstools\n",
    "cosmo = jc.Planck15(Omega_c=0.3, sigma8=0.8)\n",
    "# Creating a given redshift distribution\n",
    "pz = jc.redshift.smail_nz(0.5, 2., 1.0)\n",
    "tracer = jc.probes.WeakLensing([pz])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62a18b",
   "metadata": {},
   "source": [
    "Unsurprisingly, our guess of $\\Omega_{c}=0, \\sigma_{8}=0$ wasn't very good!\n",
    "(Check out Tuesday's `metrics.ipynb` notebook for more on $\\sigma_{8}$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70900c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = jc.angular_cl.angular_cl(cosmo, l2, [tracer])[0]\n",
    "plt.plot(l2, cell, label='Theory')\n",
    "plt.plot(l2, Pl2)\n",
    "plt.loglog()\n",
    "plt.legend()\n",
    "plt.xlabel(r'multipole $\\ell=\\pi/\\theta$ (inverse angle)')\n",
    "plt.ylabel(r'power spectrum $C_{\\ell}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907d0da8",
   "metadata": {},
   "source": [
    "## Part 1: MCMC sampling\n",
    "\n",
    "We _could_ MCMC sample this just to have something to check against the LFI results.\n",
    "_(The following does MCMC sampling with `numpyro`, with which I'm not super familiar, so you'll have to consult the documentation if you have any questions about the mechanics, sorry!)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we condition the model on obervations\n",
    "observed_model = condition(model, {'x': m_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kernel = numpyro.infer.NUTS(observed_model,\n",
    "                                 init_strategy=numpyro.infer.init_to_median,\n",
    "                                 max_tree_depth=6,\n",
    "                                 step_size=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f304345",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = numpyro.infer.MCMC(nuts_kernel, \n",
    "                          num_warmup=100, \n",
    "                          num_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d94d6f",
   "metadata": {},
   "source": [
    "This step is very slow, so I did it for you.\n",
    "Download the file from [the data directory here](https://github.com/aimalz/dsfp2022) and change the path below as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd431aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # very slow on CPU (>1 hour), might be faster on GPU (<1 hour)\n",
    "# mcmc.run(jax.random.PRNGKey(3))\n",
    "\n",
    "# res = mcmc.get_samples()\n",
    "\n",
    "# # Saving the trace\n",
    "# with open('lensing_fwd_mdl_lognorm.pickle', 'wb') as handle:\n",
    "#     pickle.dump(res, handle)#, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('lensing_fwd_mdl_lognorm.pickle', 'rb') as handle:\n",
    "    res = pickle.load(handle)#, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfbf5e1",
   "metadata": {},
   "source": [
    "Let's check out the samples!\n",
    "(The color indicates their order in the chain.\n",
    "If I'd waited for actual convergence and thrown out the burn-in, there'd be no pattern, but you can see that later samples are more tightly clustered because I was impatient.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.scatter(res['omega_c']* 0.05 + 0.3, res['sigma_8']* 0.05 + 0.8, c=np.arange(len(res['sigma_8'])));\n",
    "plt.axvline(0.3)\n",
    "plt.axhline(0.8)\n",
    "plt.xlabel(r'$\\Omega_c$')\n",
    "plt.ylabel(r'$\\sigma_8$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2afd49",
   "metadata": {},
   "source": [
    "We can also plot the mean value of the latent variable, but it's not very interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fddcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res['z'].mean(axis=0),vmin=-4,vmax=4); \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9112e0c",
   "metadata": {},
   "source": [
    "Let's generate a map for our (bad) pror cosmology with the MCMC samples' preferred latent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c27032",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_model = condition(model, {'z': res['z'].mean(axis=0), 'omega_c': 0., 'sigma_8': 0.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09fabff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_map_rec = seed(conditional_model, jax.random.PRNGKey(2))\n",
    "m_data_rec = sample_map_rec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m_data_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b04325",
   "metadata": {},
   "source": [
    "We can then look at the lensing map predicted by the mean values of the cosmological parameters _(I think)_.\n",
    "Yeah, that looks pretty reasonable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trace = trace(sample_map_rec).get_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model_trace['x']['fn'].mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c02f19",
   "metadata": {},
   "source": [
    "## CHALLENGE: ABC\n",
    "\n",
    "Write an ABC version of the above inference.\n",
    "The steps are as follows:\n",
    "![algorithm](m_stx894alg1.jpeg \"ABC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4832e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38b9cd65",
   "metadata": {},
   "source": [
    "## Part 2: Simulation-based inference\n",
    "\n",
    "Let's pretend we don't know how to use `numpyro` to sample the `jax` likelihood with MCMC sampling _(easy enough because it's basically magic to me)_ and instead use simulation-based inference.\n",
    "Better yet, let's pretend we don't know the physics to generate weak lensing observations at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29639522",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DemoSBI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6fc3cc",
   "metadata": {},
   "source": [
    "First, we need to establish an observation against which we're going to compare our predictions to constrain the cosmological parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52545aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = jc.Planck15()                  # Create a cosmology with default parameters\n",
    "nz = jc.redshift.smail_nz(1., 2,  0.75, \n",
    "                  gals_per_arcmin2=6)  # Create a Smail redshift distribution\n",
    "tracer = jc.probes.WeakLensing([nz])   # Define a lensing probe\n",
    "\n",
    "# Let's build an array of parameters \n",
    "fid_params = np.array([cosmo.Omega_c, cosmo.sigma8]) \n",
    "\n",
    "# An array of ells\n",
    "ell = jnp.logspace(2, np.log10(2_000), 20)\n",
    "\n",
    "# Computing the mean and covariance matrix for this cosmology and this tracer\n",
    "mu, cov = jc.angular_cl.gaussian_cl_covariance_and_mean(cosmo, ell, [tracer], f_sky=0.125);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d4b7fe",
   "metadata": {},
   "source": [
    "The implicit likelihood is for the summary statistic given cosmology, so $p(C_{\\ell} | \\Omega_{c}, \\sigma_{8})$.\n",
    "This is essentially the simulator!\n",
    "It doesn't even know about weak lensing mass maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b433da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function that will sample a Cl for a given cosmology\n",
    "@jax.jit\n",
    "def sample_likelihood(params, key):\n",
    "    cosmo = jc.Planck15(Omega_c=params[0], sigma8=params[1])\n",
    "    mu = jc.angular_cl.angular_cl(cosmo, ell, [tracer]).flatten() \n",
    "    dist = tfd.MultivariateNormalDiag(loc=mu, \n",
    "                                    scale_diag=jnp.sqrt(jnp.diag(cov)))\n",
    "    return dist.sample(seed=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee6578",
   "metadata": {},
   "source": [
    "The sumamry statistic is pretty stable over random realizations of data given the same cosmological parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw measured cls for different seeds at the fiducial cosmology\n",
    "plt.plot(ell, sample_likelihood(fid_params, jax.random.PRNGKey(0)))\n",
    "plt.plot(ell, sample_likelihood(fid_params, jax.random.PRNGKey(1)))\n",
    "plt.plot(ell, sample_likelihood(fid_params, jax.random.PRNGKey(2)))\n",
    "plt.loglog()\n",
    "\n",
    "plt.plot(ell, mu, '--', 'fiducial cosmology')\n",
    "\n",
    "plt.xlabel(r'multipole $\\ell=\\pi/\\theta$ (inverse angle)')\n",
    "plt.ylabel(r'power spectrum $C_{\\ell}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb21791",
   "metadata": {},
   "source": [
    "We can use this spiffy canned `sbi` package to  perform the inference.\n",
    "[Here's a tutorial showing its options](https://github.com/mackelab/sbi/blob/main/tutorials/00_getting_started.ipynb).\n",
    "All we need is a `simulator` and a `prior`.\n",
    "Let's use a flat prior on both cosmological parameters and the summary statistic likelihood sampler defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc870c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dim = 2\n",
    "prior = utils.BoxUniform(low=0.1 * torch.ones(num_dim), high=1 * torch.ones(num_dim))\n",
    "\n",
    "def simulator(parameter_set):\n",
    "    return sample_likelihood(parameter_set.cpu().detach().numpy(), next(seq)).to_py()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5dd7bd",
   "metadata": {},
   "source": [
    "With these ingredients, we can define a posterior, which is a model the `sbi` package trains by a process it confusingly calls inference, by generating and then effectively interpolating over many instances of parameters drawn from the prior and observations drawn from the `simulator` and `prior` -- this is not our inference step!\n",
    "Feel free to experiment with the different options for the \"inference\" approach (`SNPE`, `SNLE`, `SNRE`).\n",
    "For our purposes, they all correspond to \"LFI\" and not \"ABC.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes minutes on laptop\n",
    "posterior = infer(simulator, prior, method=\"SNPE\", num_simulations=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d71ed8e",
   "metadata": {},
   "source": [
    "Let's get down to business and make our one real observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a28047",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = sample_likelihood(fid_params, jax.random.PRNGKey(0)).to_py()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ad3b3",
   "metadata": {},
   "source": [
    "Now we can condition on our observation and sample the trained posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa26ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = posterior.sample((10000,), x=observation)\n",
    "log_probability = posterior.log_prob(samples, x=observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797b52c6",
   "metadata": {},
   "source": [
    "The samples can be treated just like MCMC samples (see Tuesday's `metrics.ipynb` notebook for more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce26ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ChainConsumer()\n",
    "c.add_chain(samples.cpu().detach().numpy(), parameters=[\"$\\Omega_c$\", \"$\\sigma_8$\"], name='SBI')\n",
    "\n",
    "fig = c.plotter.plot(figsize=\"column\", truth=fid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabbd7b",
   "metadata": {},
   "source": [
    "These look like very reasonable constraints on the cosmological parameters in that they have the right physical degeneracy -- without knowing any physics! -- but they're still quite broad.\n",
    "Can you make them better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949c953a",
   "metadata": {},
   "source": [
    "## CHALLENGE: another prefab example of LFI (surprise, it's photo-$z$s!)\n",
    "\n",
    "Refer back to yesterday's `expdes-photoz.ipynb` problem set.\n",
    "[`pzflow`](https://github.com/jfcrenshaw/pzflow) is another example of a \"simulator\" for the purposes of LFI.\n",
    "Instead of using it to generate mock data, use it as an estimator following the `pzflow` tutorials from its GitHub repository and experiment with model assumptions (retrain using different data sets) to see how those affect the estimated posteriors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d80db",
   "metadata": {},
   "source": [
    "For the sake of expediency, pre-trained models of the $p(z, photometry)$ joint probability space are provided as `.pkl` files [here](https://github.com/aimalz/dsfp2022/tree/main/data), where the training sets are the [Happy/Teddy data sets](https://github.com/COINtoolbox/photoz_catalogues) (see [Beck, et al 2017](https://arxiv.org/abs/1701.08748) for full release notes), curated subsamples of the [Sloan Digital Sky Survey (SDSS) Data Release (DR) 12](https://www.sdss.org/dr12/),created by the [Cosmostatistics Initiative (COIN)](https://cosmostatistics-initiative.org/).\n",
    "(Recall that the training set is a sort of prior on the relationship between redshift and photometry.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ['happy', 'teddy']:\n",
    "    for lett in ['A', 'B', 'C', 'D']:     \n",
    "        print(name+lett)\n",
    "        flow = Flow(file=name+lett+'flow.pkl')\n",
    "        . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4863c",
   "metadata": {},
   "source": [
    "Use the totally unrelated data that comes with `pzflow` as a test set on which you want to estimate redshifts from photometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f8ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_min, z_max = 0., 1.5\n",
    "r_min, r_max = 10., 25.\n",
    "\n",
    "from pzflow.examples import get_galaxy_data\n",
    "\n",
    "data = get_galaxy_data()\n",
    "\n",
    "# restrict to Happy/Teddy range for coverage in demo\n",
    "data = data[(data['redshift'] > z_min) & (data['redshift'] < z_max) & (data['r'] > r_min) & (data['r'] < r_max)]\n",
    "\n",
    "# normalize\n",
    "data = data\n",
    "\n",
    "# use fewer bands to be able to compare with Happy/Teddy\n",
    "data = data[['redshift', 'u', 'g', 'r', 'i', 'z']]\n",
    "\n",
    "# convert magnitudes to a reference magnitude and colors\n",
    "data['u-g'] = data['u'] - data['g']\n",
    "data['g-r'] = data['g'] - data['r']\n",
    "data['r-i'] = data['r'] - data['i']\n",
    "data['i-z'] = data['i'] - data['z']\n",
    "\n",
    "# save the new set\n",
    "data = data[['redshift', 'r', 'u-g', 'g-r', 'r-i', 'i-z']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3435748",
   "metadata": {},
   "source": [
    "This is the syntax for how to estimate posteriors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02eec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "granularity = 100\n",
    "grid = np.linspace(z_min, z_max, granularity)\n",
    "\n",
    "chosen = 42\n",
    "\n",
    "galaxy = data.iloc[[chosen]]\n",
    "pdf = flow.posterior(galaxy, column=\"redshift\", grid=grid)\n",
    "\n",
    "plt.plot(grid, pdf[0], label='Posterior')\n",
    "plt.axvline(galaxy['redshift'].values[0], 0, 1, c='C3', label='True redshift')\n",
    "plt.legend()\n",
    "plt.xlabel(\"redshift\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f0887",
   "metadata": {},
   "source": [
    "Now you have everything you need to experiment with a likelihood-free way to estimate redshifts from photometry!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e77ccd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d220a7c",
   "metadata": {},
   "source": [
    "As a bonus, you can give `flow.posterior()` an extra keyword argument, `err_samples`, to make it extra Bayesian, if your test set data have columns named `[col]_err` for original column names `[col]`.\n",
    "(You can populate these heuristically as, e.g. 1% or 10% of the original `[col]` values.)\n",
    "Then you can experiment with different numbers of `err_samples`, which takes into account observation errors on the photometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3be20e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSFP (Python 3)",
   "language": "python",
   "name": "dsfp_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
